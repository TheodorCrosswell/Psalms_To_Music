{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63c5b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import cmudict\n",
    "import re\n",
    "from pprint import pprint\n",
    "import pyphen\n",
    "# Download the cmudict data if you haven't already\n",
    "# import nltk\n",
    "# try:\n",
    "#     nltk.data.find(\"corpora/cmudict.zip\")\n",
    "# except nltk.downloader.DownloadError:\n",
    "#     nltk.download(\"cmudict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8e371eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words: 13725\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/kjv.txt\", \"r\") as file:\n",
    "    kjv_text = file.read()\n",
    "\n",
    "clean_kjv_text = re.sub(r\"[.,:;'()?!|]\", \"\", kjv_text)\n",
    "\n",
    "all_kjv_words = set()\n",
    "\n",
    "for word in clean_kjv_text.split():\n",
    "    all_kjv_words.add(word)\n",
    "\n",
    "all_kjv_words = list(all_kjv_words)\n",
    "\n",
    "print(f\"Total number of unique words: {len(all_kjv_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d887f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Stats ---\n",
      "{'Capital letter, skipped': 3098,\n",
      " 'Immediately recognized': 8280,\n",
      " \"Removed 'est' or 'eth', recognized\": 776,\n",
      " \"Removed 's' from end, recognized\": 192,\n",
      " 'Removed 1 extra character from the end, recognized': 45,\n",
      " \"Replaced 'iest' or 'ieth' with 'y', recognized\": 20,\n",
      " \"Replaced 'or'/'ors' with 'er', recognized\": 2,\n",
      " \"Replaced British 'u' and removed 'est' or 'eth', recognized\": 5,\n",
      " \"Replaced British 'u', recognized\": 33,\n",
      " 'Unrecognized and not caught by filters': 1274}\n"
     ]
    }
   ],
   "source": [
    "pronunciations = cmudict.dict()\n",
    "\n",
    "\n",
    "def count_syllables_cmudict(word: str, pronunciations_dict: dict) -> int:\n",
    "    \"\"\"Counts the syllables in a word using NLTK's CMUDict.\"\"\"\n",
    "    word_lower = word.lower()\n",
    "    if word_lower not in pronunciations_dict:\n",
    "        return 0\n",
    "    # A word can have multiple pronunciations; we'll use the first one.\n",
    "    return len(\n",
    "        [\n",
    "            phoneme\n",
    "            for phoneme in pronunciations_dict[word_lower][0]\n",
    "            if phoneme[-1].isdigit()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def process_word(word: str, pronunciations_dict: dict, stats: dict) -> None:\n",
    "    \"\"\"\n",
    "    Checks a word against CMUDict and various transformations, updating stats.\n",
    "    Returns the word if it remains unrecognized, otherwise returns None.\n",
    "    \"\"\"\n",
    "    if count_syllables_cmudict(word, pronunciations_dict) > 0:\n",
    "        stats[\"Immediately recognized\"] += 1\n",
    "        return None\n",
    "\n",
    "    if not str.islower(word):\n",
    "        stats[\"Capital letter, skipped\"] += 1\n",
    "        return None\n",
    "\n",
    "    # --- Suffix and Transformation Checks ---\n",
    "\n",
    "    # Rule: Remove 'est' or 'eth'\n",
    "    if word.endswith((\"eth\", \"est\")):\n",
    "        base_word_3 = word[:-3]\n",
    "        base_word_2 = word[:-2]\n",
    "        if (\n",
    "            count_syllables_cmudict(base_word_3, pronunciations_dict) > 0\n",
    "            or count_syllables_cmudict(base_word_2, pronunciations_dict) > 0\n",
    "        ):\n",
    "            stats[\"Removed 'est' or 'eth', recognized\"] += 1\n",
    "            return None \n",
    "\n",
    "    # Rule: Remove 's' from end\n",
    "    if word.endswith((\"s\")):\n",
    "        transformed_word = word[:-1]\n",
    "        if count_syllables_cmudict(transformed_word, pronunciations_dict) > 0:\n",
    "            stats[\"Removed 's' from end, recognized\"] += 1\n",
    "            return None\n",
    "\n",
    "    # Rule: Remove 1 extra character from the end (often after suffix removal fails)\n",
    "    if word.endswith((\"eth\", \"est\")):\n",
    "        base_word_4 = word[:-4]\n",
    "        if count_syllables_cmudict(base_word_4, pronunciations_dict) > 0:\n",
    "            stats[\"Removed 1 extra character from the end, recognized\"] += 1\n",
    "            return None\n",
    "\n",
    "    # Rule: Replace 'iest' or 'ieth' with 'y'\n",
    "    if word.endswith((\"ieth\", \"iest\")):\n",
    "        transformed_word = re.sub(r\"(iest|ieth)$\", \"y\", word)\n",
    "        if count_syllables_cmudict(transformed_word, pronunciations_dict) > 0:\n",
    "            stats[\"Replaced 'iest' or 'ieth' with 'y', recognized\"] += 1\n",
    "            return None\n",
    "\n",
    "    # Rule: Replace British 'our' with 'or'\n",
    "    if \"our\" in word:\n",
    "        transformed_word = re.sub(\n",
    "            r\"our\", \"or\", word\n",
    "        )\n",
    "        if count_syllables_cmudict(transformed_word, pronunciations_dict) > 0:\n",
    "            stats[\"Replaced British 'u', recognized\"] += 1\n",
    "            return None\n",
    "\n",
    "    # Rule: Replace British 'our' with 'or'\n",
    "    if \"our\" in word and word.endswith((\"est\", \"eth\")):\n",
    "        transformed_word = re.sub(r\"our\\w*\", \"or\", word)\n",
    "        if count_syllables_cmudict(transformed_word, pronunciations_dict) > 0:\n",
    "            stats[\"Replaced British 'u' and removed 'est' or 'eth', recognized\"] += 1\n",
    "            return None\n",
    "\n",
    "    # Rule: Replace 'or'/'ors' with 'er'\n",
    "    if word.endswith((\"or\", \"ors\")):\n",
    "        transformed_word = re.sub(r\"or\\w?\", \"er\", word)\n",
    "        if count_syllables_cmudict(transformed_word, pronunciations_dict) > 0:\n",
    "            stats[\"Replaced 'or'/'ors' with 'er', recognized\"] += 1\n",
    "            return None\n",
    "\n",
    "    # If no rules matched and the word is unrecognized\n",
    "    stats[\"Unrecognized and not caught by filters\"] += 1\n",
    "    return word\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "difficult_words = []\n",
    "word_stats = {\n",
    "    \"Immediately recognized\": 0,\n",
    "    \"Capital letter, skipped\": 0,\n",
    "    \"Unrecognized and not caught by filters\": 0,\n",
    "    \"Removed 'est' or 'eth', recognized\": 0,\n",
    "    \"Replaced 'iest' or 'ieth' with 'y', recognized\": 0,\n",
    "    \"Removed 1 extra character from the end, recognized\": 0,\n",
    "    \"Replaced British 'u', recognized\": 0,\n",
    "    \"Replaced British 'u' and removed 'est' or 'eth', recognized\": 0,\n",
    "    \"Replaced 'or'/'ors' with 'er', recognized\": 0,\n",
    "    \"Removed 's' from end, recognized\": 0,\n",
    "\n",
    "}\n",
    "\n",
    "for word in all_kjv_words:\n",
    "    unrecognized = process_word(word, pronunciations, word_stats)\n",
    "    if unrecognized:\n",
    "        difficult_words.append(unrecognized)\n",
    "\n",
    "print(\"\\n--- Stats ---\")\n",
    "pprint(word_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78cc70fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: syllables\n",
      "eveningtide: 2\n",
      "forbeareth: 2\n",
      "sawn: 1\n",
      "haply: 2\n",
      "viol: 2\n",
      "cloven: 1\n",
      "appertaineth: 3\n",
      "stumblingblocks: 3\n",
      "menstealers: 3\n",
      "scall: 1\n"
     ]
    }
   ],
   "source": [
    "hyphen_gb = pyphen.Pyphen(lang=\"en_GB\")\n",
    "hyphen_us = pyphen.Pyphen(lang=\"en_US\")\n",
    "\n",
    "def count_syllables_pyphen(word: str):\n",
    "    hyphenated_word_gb = hyphen_gb.inserted(word)\n",
    "    syllable_count_gb = len(hyphenated_word_gb.split(\"-\"))\n",
    "    hyphenated_word_us = hyphen_us.inserted(word)\n",
    "    syllable_count_us = len(hyphenated_word_us.split(\"-\"))\n",
    "    return max(syllable_count_us, syllable_count_gb)\n",
    "\n",
    "print(\"word: syllables\")\n",
    "\n",
    "# My observation: in most cases, the best answer is the highest of the 2.\n",
    "# Therefore, the best option would be to get the higher count.\n",
    "for word in difficult_words[0:10]:\n",
    "    word = re.sub(\"-\", \"\", word)\n",
    "    print(f\"{word}: {count_syllables_pyphen(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f89cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling: 2\n",
      "Zacchaeus: 4\n",
      "Whoso: 1\n",
      "spoiler: 2\n",
      "eveningtide: 2\n",
      "Arpad: 1\n",
      "forbeareth: 2\n",
      "Aharah: 2\n",
      "offered: 2\n",
      "idleness: 3\n"
     ]
    }
   ],
   "source": [
    "pronunciations = cmudict.dict()\n",
    "def get_syllable_count(word:str):\n",
    "    syllable_count = count_syllables_cmudict(word, pronunciations)\n",
    "    if syllable_count == 0:\n",
    "        syllable_count = count_syllables_pyphen(word)\n",
    "    return syllable_count\n",
    "\n",
    "for word in all_kjv_words[0:10]:\n",
    "    print(f\"{word}: {get_syllable_count(word)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
